{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ca024db-0240-4bc1-a901-6169b98bdf2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T15:39:41.588761Z",
     "iopub.status.busy": "2025-03-05T15:39:41.588641Z",
     "iopub.status.idle": "2025-03-05T15:39:44.426923Z",
     "shell.execute_reply": "2025-03-05T15:39:44.426364Z",
     "shell.execute_reply.started": "2025-03-05T15:39:41.588746Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Image-related utilities\n",
    "from torchvision.io import decode_image, read_image\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Import models\n",
    "from torchvision.models import alexnet, AlexNet_Weights\n",
    "from torchvision.models import vgg19, VGG19_Weights\n",
    "\n",
    "# Dataset\n",
    "from torchvision.datasets import Imagenette\n",
    "\n",
    "# LRP package\n",
    "from src.lrp import LRPModel\n",
    "from src.data import get_data_loader\n",
    "\n",
    "# Utils\n",
    "import argparse\n",
    "import time\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6eb19d0-a73e-48c0-b829-8ed3f44e8ef2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T15:39:44.427574Z",
     "iopub.status.busy": "2025-03-05T15:39:44.427364Z",
     "iopub.status.idle": "2025-03-05T15:39:44.430456Z",
     "shell.execute_reply": "2025-03-05T15:39:44.430022Z",
     "shell.execute_reply.started": "2025-03-05T15:39:44.427560Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define custom colormap\n",
    "colors = [\"white\", \"red\"]  # Transition from white to red\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\"white_red\", colors, N=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfda1d7f-2d4d-4c97-8496-7285707668b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T15:39:44.431214Z",
     "iopub.status.busy": "2025-03-05T15:39:44.431006Z",
     "iopub.status.idle": "2025-03-05T15:39:44.435650Z",
     "shell.execute_reply": "2025-03-05T15:39:44.435205Z",
     "shell.execute_reply.started": "2025-03-05T15:39:44.431197Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_relevance_scores(\n",
    "    x: torch.tensor, r: torch.tensor, name: str\n",
    ") -> None:\n",
    "    \"\"\"Plots results from layer-wise relevance propagation next to original image.\n",
    "\n",
    "    Method currently accepts only a batch size of one.\n",
    "\n",
    "    Args:\n",
    "        x: Original image.\n",
    "        r: Relevance scores for original image.\n",
    "        name: Image name.\n",
    "        config: Argparse namespace object.\n",
    "\n",
    "    \"\"\"\n",
    "    output_dir = \"./output/\"\n",
    "\n",
    "    max_fig_size = 20\n",
    "\n",
    "    _, _, img_height, img_width = x.shape\n",
    "    max_dim = max(img_height, img_width)\n",
    "    fig_height, fig_width = (\n",
    "        max_fig_size * img_height / max_dim,\n",
    "        max_fig_size * img_width / max_dim,\n",
    "    )\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(fig_width, fig_height))\n",
    "\n",
    "    x = x[0].squeeze().permute(1, 2, 0).detach().cpu()\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    axes[0].imshow(x)\n",
    "    axes[0].set_axis_off()\n",
    "\n",
    "    r_min = r.min()\n",
    "    r_max = r.max()\n",
    "    r = (r - r_min) / (r_max - r_min)\n",
    "    axes[1].imshow(r, cmap='hot')\n",
    "    axes[1].set_axis_off()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/image_{name}.png\", bbox_inches=\"tight\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4c1f47f-f9d3-4858-b05a-f81f6f4826af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T15:39:44.436627Z",
     "iopub.status.busy": "2025-03-05T15:39:44.436501Z",
     "iopub.status.idle": "2025-03-05T15:39:44.440040Z",
     "shell.execute_reply": "2025-03-05T15:39:44.439727Z",
     "shell.execute_reply.started": "2025-03-05T15:39:44.436614Z"
    }
   },
   "outputs": [],
   "source": [
    "def per_image_lrp():\n",
    "    \"\"\"Test function that plots heatmaps for images placed in the input folder.\n",
    "\n",
    "    Images have to be placed in their corresponding class folders.\n",
    "\n",
    "    Args:\n",
    "        config: Argparse namespace object.\n",
    "\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "    print(f\"Using: {device}\\n\")\n",
    "\n",
    "    data_loader = get_data_loader()\n",
    "    \n",
    "    model = vgg19(weights=VGG19_Weights.DEFAULT)\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    lrp_model = LRPModel(model=model, top_k=0.02)\n",
    "\n",
    "    for i, (x, y) in enumerate(data_loader):\n",
    "        x = x.to(device)\n",
    "        # y = y.to(device)  # here not used as method is unsupervised.\n",
    "\n",
    "        t0 = time.time()\n",
    "        r = lrp_model.forward(x)\n",
    "        print(\"{time:.2f} FPS\".format(time=(1.0 / (time.time() - t0))))\n",
    "\n",
    "        plot_relevance_scores(x=x, r=r, name=str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73c3664c-4964-43d3-9fad-c5f48eb20212",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T15:39:44.440833Z",
     "iopub.status.busy": "2025-03-05T15:39:44.440705Z",
     "iopub.status.idle": "2025-03-05T15:39:59.661269Z",
     "shell.execute_reply": "2025-03-05T15:39:59.660772Z",
     "shell.execute_reply.started": "2025-03-05T15:39:44.440820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n",
      "\n",
      "2.28 FPS\n",
      "7.60 FPS\n",
      "7.55 FPS\n",
      "7.69 FPS\n",
      "11.59 FPS\n",
      "10.10 FPS\n",
      "6.67 FPS\n",
      "8.52 FPS\n",
      "5.34 FPS\n",
      "5.29 FPS\n",
      "8.42 FPS\n",
      "7.23 FPS\n",
      "6.77 FPS\n",
      "4.33 FPS\n",
      "5.80 FPS\n",
      "4.77 FPS\n",
      "6.26 FPS\n",
      "1.98 FPS\n",
      "6.81 FPS\n",
      "23.22 FPS\n"
     ]
    }
   ],
   "source": [
    "per_image_lrp()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
