{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ca024db-0240-4bc1-a901-6169b98bdf2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T15:15:50.538056Z",
     "iopub.status.busy": "2025-04-19T15:15:50.537836Z",
     "iopub.status.idle": "2025-04-19T15:15:52.652440Z",
     "shell.execute_reply": "2025-04-19T15:15:52.651869Z",
     "shell.execute_reply.started": "2025-04-19T15:15:50.538016Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Image-related utilities\n",
    "from torchvision.io import decode_image, read_image\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Import models\n",
    "from torchvision.models import alexnet, AlexNet_Weights\n",
    "from torchvision.models import vgg19, VGG19_Weights\n",
    "\n",
    "# Dataset\n",
    "from torchvision.datasets import Imagenette\n",
    "\n",
    "# LRP package\n",
    "from src.lrp import LRPModel\n",
    "from src.data import get_data_loader\n",
    "\n",
    "# Utils\n",
    "import argparse\n",
    "import time\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7fbb38d-2b07-43b2-9c47-e1054119c3e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T15:15:52.653805Z",
     "iopub.status.busy": "2025-04-19T15:15:52.653415Z",
     "iopub.status.idle": "2025-04-19T15:15:52.656543Z",
     "shell.execute_reply": "2025-04-19T15:15:52.656030Z",
     "shell.execute_reply.started": "2025-04-19T15:15:52.653791Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageFolderWithPaths(ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        # get original tuple (image, label)\n",
    "        original_tuple = super().__getitem__(index)\n",
    "        # get image path\n",
    "        path = self.imgs[index][0]\n",
    "        # make new tuple (image, label, path)\n",
    "        tuple_with_path = original_tuple + (path,)\n",
    "        return tuple_with_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6eb19d0-a73e-48c0-b829-8ed3f44e8ef2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T15:15:52.657160Z",
     "iopub.status.busy": "2025-04-19T15:15:52.657039Z",
     "iopub.status.idle": "2025-04-19T15:15:52.671523Z",
     "shell.execute_reply": "2025-04-19T15:15:52.670647Z",
     "shell.execute_reply.started": "2025-04-19T15:15:52.657147Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define custom colormap\n",
    "colors = [\"white\", \"red\"]  # Transition from white to red\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\"white_red\", colors, N=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfda1d7f-2d4d-4c97-8496-7285707668b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T15:15:52.672879Z",
     "iopub.status.busy": "2025-04-19T15:15:52.672700Z",
     "iopub.status.idle": "2025-04-19T15:15:52.677901Z",
     "shell.execute_reply": "2025-04-19T15:15:52.677324Z",
     "shell.execute_reply.started": "2025-04-19T15:15:52.672867Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_relevance_scores(\n",
    "    x: torch.tensor, r: torch.tensor, input_path: str\n",
    ") -> None:\n",
    "    \"\"\"Plots results from layer-wise relevance propagation next to original image.\n",
    "\n",
    "    Method currently accepts only a batch size of one.\n",
    "\n",
    "    Args:\n",
    "        x: Original image.\n",
    "        r: Relevance scores for original image.\n",
    "        name: Image name.\n",
    "        config: Argparse namespace object.\n",
    "\n",
    "    \"\"\"\n",
    "    output_root = \"./output\"\n",
    "    input_root = \"./input\"\n",
    "\n",
    "    # Reconstruct relative path from input\n",
    "    rel_path = os.path.relpath(input_path, input_root)  # e.g., \"church/image1.jpg\"\n",
    "    rel_path = os.path.splitext(rel_path)[0] + \".png\"   # \"church/image1.png\"\n",
    "    output_path = os.path.join(output_root, rel_path)\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    max_fig_size = 20\n",
    "\n",
    "    _, _, img_height, img_width = x.shape\n",
    "    max_dim = max(img_height, img_width)\n",
    "    fig_height, fig_width = (\n",
    "        max_fig_size * img_height / max_dim,\n",
    "        max_fig_size * img_width / max_dim,\n",
    "    )\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(fig_width, fig_height))\n",
    "\n",
    "    x = x[0].squeeze().permute(1, 2, 0).detach().cpu()\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    axes[0].imshow(x)\n",
    "    axes[0].set_axis_off()\n",
    "\n",
    "    r_min = r.min()\n",
    "    r_max = r.max()\n",
    "    r = (r - r_min) / (r_max - r_min)\n",
    "    axes[1].imshow(r, cmap='hot')\n",
    "    axes[1].set_axis_off()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(output_path, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    torch.cuda.empty_cache()\n",
    "    del x, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4c1f47f-f9d3-4858-b05a-f81f6f4826af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T15:15:52.678693Z",
     "iopub.status.busy": "2025-04-19T15:15:52.678528Z",
     "iopub.status.idle": "2025-04-19T15:15:52.682028Z",
     "shell.execute_reply": "2025-04-19T15:15:52.681705Z",
     "shell.execute_reply.started": "2025-04-19T15:15:52.678680Z"
    }
   },
   "outputs": [],
   "source": [
    "def per_image_lrp(model):\n",
    "    \"\"\"Test function that plots heatmaps for images placed in the input folder.\n",
    "\n",
    "    Images have to be placed in their corresponding class folders.\n",
    "\n",
    "    Args:\n",
    "        config: Argparse namespace object.\n",
    "\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "    print(f\"Using: {device}\\n\")\n",
    "\n",
    "    data_loader = get_data_loader()\n",
    "    \n",
    "    model = model\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    lrp_model = LRPModel(model=model, top_k=0.02)\n",
    "\n",
    "    for i, (x, y, paths) in enumerate(data_loader):\n",
    "        x = x.to(device)\n",
    "        # y = y.to(device)  # here not used as method is unsupervised.\n",
    "        # Get the original filename\n",
    "        image_path = paths[0]\n",
    "        #image_name = os.path.basename(image_path)\n",
    "        #image_name_wo_ext = os.path.splitext(image_name)[0]\n",
    "        \n",
    "        t0 = time.time()\n",
    "        r = lrp_model.forward(x)\n",
    "        print(\"{time:.2f} FPS\".format(time=(1.0 / (time.time() - t0))))\n",
    "\n",
    "        plot_relevance_scores(x=x, r=r, input_path=image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73c3664c-4964-43d3-9fad-c5f48eb20212",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T15:15:52.682739Z",
     "iopub.status.busy": "2025-04-19T15:15:52.682554Z",
     "iopub.status.idle": "2025-04-19T15:16:59.151665Z",
     "shell.execute_reply": "2025-04-19T15:16:59.151078Z",
     "shell.execute_reply.started": "2025-04-19T15:15:52.682726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n",
      "\n",
      "3.30 FPS\n",
      "7.87 FPS\n",
      "8.23 FPS\n",
      "7.28 FPS\n",
      "7.60 FPS\n",
      "8.22 FPS\n",
      "7.13 FPS\n",
      "7.66 FPS\n",
      "7.87 FPS\n",
      "4.47 FPS\n",
      "6.86 FPS\n",
      "3.94 FPS\n",
      "7.26 FPS\n",
      "2.91 FPS\n",
      "7.82 FPS\n",
      "35.99 FPS\n",
      "40.68 FPS\n",
      "4.10 FPS\n",
      "7.48 FPS\n",
      "6.47 FPS\n",
      "6.83 FPS\n",
      "44.27 FPS\n",
      "7.03 FPS\n",
      "5.52 FPS\n",
      "7.26 FPS\n",
      "7.60 FPS\n",
      "1.15 FPS\n",
      "6.77 FPS\n",
      "7.38 FPS\n",
      "6.59 FPS\n",
      "7.89 FPS\n",
      "5.77 FPS\n",
      "7.05 FPS\n",
      "6.82 FPS\n",
      "7.60 FPS\n",
      "6.79 FPS\n",
      "7.02 FPS\n",
      "4.30 FPS\n",
      "6.96 FPS\n",
      "7.21 FPS\n",
      "7.04 FPS\n",
      "1.52 FPS\n",
      "6.45 FPS\n",
      "5.78 FPS\n",
      "5.11 FPS\n",
      "7.15 FPS\n",
      "5.07 FPS\n",
      "6.79 FPS\n",
      "6.94 FPS\n",
      "7.03 FPS\n",
      "7.34 FPS\n",
      "10.47 FPS\n",
      "6.70 FPS\n",
      "7.11 FPS\n",
      "7.56 FPS\n",
      "5.66 FPS\n",
      "6.62 FPS\n",
      "7.78 FPS\n",
      "3.16 FPS\n",
      "7.85 FPS\n",
      "7.99 FPS\n",
      "5.81 FPS\n",
      "5.40 FPS\n",
      "6.23 FPS\n",
      "16.08 FPS\n",
      "10.64 FPS\n",
      "9.11 FPS\n",
      "9.16 FPS\n",
      "9.09 FPS\n",
      "25.25 FPS\n",
      "9.06 FPS\n",
      "16.06 FPS\n",
      "6.52 FPS\n",
      "7.14 FPS\n",
      "6.25 FPS\n",
      "7.37 FPS\n",
      "8.88 FPS\n",
      "7.99 FPS\n",
      "9.20 FPS\n",
      "36.79 FPS\n",
      "6.65 FPS\n",
      "21.35 FPS\n",
      "8.01 FPS\n",
      "7.41 FPS\n",
      "7.96 FPS\n",
      "7.86 FPS\n",
      "6.49 FPS\n",
      "5.57 FPS\n",
      "6.28 FPS\n",
      "4.09 FPS\n",
      "7.07 FPS\n",
      "6.85 FPS\n",
      "13.69 FPS\n",
      "4.64 FPS\n",
      "5.07 FPS\n",
      "6.23 FPS\n",
      "7.19 FPS\n",
      "6.39 FPS\n",
      "6.97 FPS\n",
      "7.13 FPS\n"
     ]
    }
   ],
   "source": [
    "# Pre-trained model\n",
    "per_image_lrp(vgg19(weights=VGG19_Weights.DEFAULT))\n",
    "\n",
    "# Retrained model\n",
    "#PATH = 'vgg19_imagenette.pth'\n",
    "#model = vgg19()\n",
    "#model.classifier[6] = torch.nn.Linear(in_features=4096, out_features=10)\n",
    "#model.load_state_dict(torch.load(PATH, weights_only=True))\n",
    "#per_image_lrp(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bb530e-fffd-4d75-8f3a-775ea7342427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
