{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ca024db-0240-4bc1-a901-6169b98bdf2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T08:43:49.339899Z",
     "iopub.status.busy": "2025-04-25T08:43:49.339773Z",
     "iopub.status.idle": "2025-04-25T08:43:51.630655Z",
     "shell.execute_reply": "2025-04-25T08:43:51.630169Z",
     "shell.execute_reply.started": "2025-04-25T08:43:49.339884Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Image-related utilities\n",
    "from torchvision.io import decode_image, read_image\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Import models\n",
    "from torchvision.models import alexnet, AlexNet_Weights\n",
    "from torchvision.models import vgg19, VGG19_Weights\n",
    "\n",
    "# Dataset\n",
    "from torchvision.datasets import Imagenette\n",
    "\n",
    "# LRP package\n",
    "from src.lrp import LRPModel\n",
    "from src.data import get_data_loader\n",
    "\n",
    "# Utils\n",
    "import argparse\n",
    "import time\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7fbb38d-2b07-43b2-9c47-e1054119c3e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T08:43:51.631872Z",
     "iopub.status.busy": "2025-04-25T08:43:51.631629Z",
     "iopub.status.idle": "2025-04-25T08:43:51.634955Z",
     "shell.execute_reply": "2025-04-25T08:43:51.634581Z",
     "shell.execute_reply.started": "2025-04-25T08:43:51.631859Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageFolderWithPaths(ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        # get original tuple (image, label)\n",
    "        original_tuple = super().__getitem__(index)\n",
    "        # get image path\n",
    "        path = self.imgs[index][0]\n",
    "        # make new tuple (image, label, path)\n",
    "        tuple_with_path = original_tuple + (path,)\n",
    "        return tuple_with_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6eb19d0-a73e-48c0-b829-8ed3f44e8ef2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T08:43:51.635633Z",
     "iopub.status.busy": "2025-04-25T08:43:51.635430Z",
     "iopub.status.idle": "2025-04-25T08:43:51.638030Z",
     "shell.execute_reply": "2025-04-25T08:43:51.637683Z",
     "shell.execute_reply.started": "2025-04-25T08:43:51.635620Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define custom colormap\n",
    "colors = [\"white\", \"red\"]  # Transition from white to red\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\"white_red\", colors, N=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfda1d7f-2d4d-4c97-8496-7285707668b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T08:43:51.638689Z",
     "iopub.status.busy": "2025-04-25T08:43:51.638533Z",
     "iopub.status.idle": "2025-04-25T08:43:51.643122Z",
     "shell.execute_reply": "2025-04-25T08:43:51.642725Z",
     "shell.execute_reply.started": "2025-04-25T08:43:51.638677Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_relevance_scores(\n",
    "    x: torch.tensor, r: torch.tensor, input_path: str\n",
    ") -> None:\n",
    "    \"\"\"Plots results from layer-wise relevance propagation next to original image.\n",
    "\n",
    "    Method currently accepts only a batch size of one.\n",
    "\n",
    "    Args:\n",
    "        x: Original image.\n",
    "        r: Relevance scores for original image.\n",
    "        name: Image name.\n",
    "        config: Argparse namespace object.\n",
    "\n",
    "    \"\"\"\n",
    "    output_root = \"./output\"\n",
    "    input_root = \"./input\"\n",
    "\n",
    "    # Reconstruct relative path from input\n",
    "    rel_path = os.path.relpath(input_path, input_root)  # e.g., \"church/image1.jpg\"\n",
    "    rel_path = os.path.splitext(rel_path)[0] + \".png\"   # \"church/image1.png\"\n",
    "    output_path = os.path.join(output_root, rel_path)\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    max_fig_size = 20\n",
    "\n",
    "    _, _, img_height, img_width = x.shape\n",
    "    max_dim = max(img_height, img_width)\n",
    "    fig_height, fig_width = (\n",
    "        max_fig_size * img_height / max_dim,\n",
    "        max_fig_size * img_width / max_dim,\n",
    "    )\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(fig_width, fig_height))\n",
    "\n",
    "    x = x[0].squeeze().permute(1, 2, 0).detach().cpu()\n",
    "    x_min = x.min()\n",
    "    x_max = x.max()\n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    axes[0].imshow(x)\n",
    "    axes[0].set_axis_off()\n",
    "\n",
    "    r_min = r.min()\n",
    "    r_max = r.max()\n",
    "    r = (r - r_min) / (r_max - r_min)\n",
    "    axes[1].imshow(r, cmap='hot')\n",
    "    axes[1].set_axis_off()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(output_path, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    torch.cuda.empty_cache()\n",
    "    del x, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4c1f47f-f9d3-4858-b05a-f81f6f4826af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T08:43:51.643880Z",
     "iopub.status.busy": "2025-04-25T08:43:51.643640Z",
     "iopub.status.idle": "2025-04-25T08:43:51.646955Z",
     "shell.execute_reply": "2025-04-25T08:43:51.646610Z",
     "shell.execute_reply.started": "2025-04-25T08:43:51.643867Z"
    }
   },
   "outputs": [],
   "source": [
    "def per_image_lrp(model):\n",
    "    \"\"\"Test function that plots heatmaps for images placed in the input folder.\n",
    "\n",
    "    Images have to be placed in their corresponding class folders.\n",
    "\n",
    "    Args:\n",
    "        config: Argparse namespace object.\n",
    "\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "    print(f\"Using: {device}\\n\")\n",
    "\n",
    "    data_loader = get_data_loader()\n",
    "    \n",
    "    model = model\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    lrp_model = LRPModel(model=model, top_k=0.02)\n",
    "\n",
    "    for i, (x, y, paths) in enumerate(data_loader):\n",
    "        x = x.to(device)\n",
    "        # y = y.to(device)  # here not used as method is unsupervised.\n",
    "        # Get the original filename\n",
    "        image_path = paths[0]\n",
    "        #image_name = os.path.basename(image_path)\n",
    "        #image_name_wo_ext = os.path.splitext(image_name)[0]\n",
    "        \n",
    "        t0 = time.time()\n",
    "        r = lrp_model.forward(x)\n",
    "        print(\"{time:.2f} FPS\".format(time=(1.0 / (time.time() - t0))))\n",
    "\n",
    "        plot_relevance_scores(x=x, r=r, input_path=image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73c3664c-4964-43d3-9fad-c5f48eb20212",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T08:43:51.647686Z",
     "iopub.status.busy": "2025-04-25T08:43:51.647426Z",
     "iopub.status.idle": "2025-04-25T08:43:54.321423Z",
     "shell.execute_reply": "2025-04-25T08:43:54.320973Z",
     "shell.execute_reply.started": "2025-04-25T08:43:51.647672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n",
      "\n",
      "2.36 FPS\n",
      "6.76 FPS\n"
     ]
    }
   ],
   "source": [
    "# Pre-trained model\n",
    "per_image_lrp(vgg19(weights=VGG19_Weights.DEFAULT))\n",
    "\n",
    "# Retrained model\n",
    "#PATH = 'vgg19_imagenette.pth'\n",
    "#model = vgg19()\n",
    "#model.classifier[6] = torch.nn.Linear(in_features=4096, out_features=10)\n",
    "#model.load_state_dict(torch.load(PATH, weights_only=True))\n",
    "#per_image_lrp(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bb530e-fffd-4d75-8f3a-775ea7342427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
