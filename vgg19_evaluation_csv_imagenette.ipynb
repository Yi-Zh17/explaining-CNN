{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7337d7e5-50ec-4865-bd2d-c050f7d6f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Image-related utilities\n",
    "from torchvision.io import decode_image, read_image\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Import models\n",
    "from torchvision.models import vgg19, VGG19_Weights\n",
    "\n",
    "# Dataset\n",
    "from torchvision.datasets import Imagenette, ImageFolder\n",
    "\n",
    "# Plotting utility\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2ff702-3cde-46a9-946a-f5409e1afafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# Read imagenette data into data loader\n",
    "#Process image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to VGG19 input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Same normalization as ImageNet\n",
    "])\n",
    "imagenette_data = ImageFolder(root='/home/yi/Downloads/imagenette2/val', transform=transform)\n",
    "data_loader = torch.utils.data.DataLoader(imagenette_data, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81d9c16-7dc4-4c7f-b706-0bedf1f10603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For pre-trained model\n",
    "# Map number to class name\n",
    "label_to_class = {\n",
    "    0: \"English springer\",\n",
    "    1: \"French horn\",\n",
    "    2: \"cassette player\",\n",
    "    3: \"chain saw\",\n",
    "    4: \"church\",\n",
    "    5: \"garbage truck\",\n",
    "    6: \"gas pump\",\n",
    "    7: \"golf ball\",\n",
    "    8: \"parachute\",\n",
    "    9: \"tench\"\n",
    "}\n",
    "\n",
    "label_to_id = {\n",
    "    0: 217,\n",
    "    1: 566,\n",
    "    2: 482, \n",
    "    3: 491,\n",
    "    4: 497,\n",
    "    5: 569,\n",
    "    6: 571, \n",
    "    7: 574,\n",
    "    8: 701, \n",
    "    9: 0\n",
    "}\n",
    "\n",
    "# For retrained model\n",
    "# Manually rewire predicted class_id to class\n",
    "pred_to_class = {\n",
    "    1: 'English springer',\n",
    "    2: 'cassette player',\n",
    "    3: 'chain saw',\n",
    "    4: 'church',\n",
    "    5: 'French horn',\n",
    "    6: 'garbage truck',\n",
    "    7: 'gas pump',\n",
    "    8: 'golf ball',\n",
    "    9: 'parachute',\n",
    "    0: 'tench'\n",
    "}\n",
    "\n",
    "label_rewire = {\n",
    "    0: 1,\n",
    "    1: 5, \n",
    "    2: 2,\n",
    "    3: 3,\n",
    "    4: 4,\n",
    "    5: 6,\n",
    "    6: 7,\n",
    "    7: 8,\n",
    "    8: 9,\n",
    "    9: 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b057cf5-ae81-4adf-a96f-96210a38c079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-trained model\n",
    "weights = VGG19_Weights.DEFAULT\n",
    "model = vgg19(weights=weights).to(device)\n",
    "model.eval()\n",
    "\n",
    "# Retrained model\n",
    "'''\n",
    "PATH = 'vgg19_imagenette.pth'\n",
    "model = vgg19()\n",
    "model.classifier[6] = torch.nn.Linear(in_features=4096, out_features=10)\n",
    "model.load_state_dict(torch.load(PATH, weights_only=True))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f62d333-1eb4-452d-acd8-b4bd9f0b1548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation (output to csv)\n",
    "def evaluate(data_loader, PATH):\n",
    "    img_path = []\n",
    "    true_label = []\n",
    "    predicted_label = []\n",
    "    confidence = []\n",
    "    true_confidence = []\n",
    "    correctness = []\n",
    "    \n",
    "    image_paths = [data_loader.dataset.samples[i][0] for i in range(len(data_loader.dataset))]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (img, label) in enumerate(tqdm(data_loader, desc=\"Evaluating\", unit=\"images\")):\n",
    "            # Retrieve image\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            # Prediction\n",
    "            prediction = model(img).squeeze(0).softmax(0)\n",
    "            class_id = prediction.argmax().item()\n",
    "            score = prediction[class_id].item()\n",
    "            true_score = prediction[label_rewire[label.item()]].item()\n",
    "            \n",
    "            # Correct?\n",
    "            #category_name = weights.meta[\"categories\"][class_id]\n",
    "            \n",
    "            # Extract class names from the dataset\n",
    "            id_to_class = {v: k for k, v in imagenette_data.class_to_idx.items()}  # Reverse mapping\n",
    "            # Get predicted category name\n",
    "            category_name = pred_to_class[class_id]\n",
    "            # Check if prediction is correct\n",
    "            correct = 'y' if category_name == id_to_class[label.item()] else 'n'\n",
    "            \n",
    "            # Log\n",
    "            img_path.append(image_paths[idx])\n",
    "            true_label.append(id_to_class[label.item()])\n",
    "            predicted_label.append(category_name)\n",
    "            confidence.append(score)\n",
    "            true_confidence.append(true_score)\n",
    "            correctness.append(correct)\n",
    "    \n",
    "    # Dictionary of logs\n",
    "    dict = {'image': img_path, 'true label': true_label, 'predicted label': predicted_label,\n",
    "            'confidence score': confidence, 'true confidence score': true_confidence, 'correct': correctness}\n",
    "    df = pd.DataFrame(dict)\n",
    "    df.to_csv(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09881061-9f11-418b-8909-c1401a8b4967",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print evaluation accuracy\n",
    "print('Evaluation accuracy: ', round(len(df[df['correct'] == 'y']) / len(df), 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
