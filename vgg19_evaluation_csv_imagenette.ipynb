{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7337d7e5-50ec-4865-bd2d-c050f7d6f6c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T10:37:40.607130Z",
     "iopub.status.busy": "2025-03-20T10:37:40.606884Z",
     "iopub.status.idle": "2025-03-20T10:37:43.088600Z",
     "shell.execute_reply": "2025-03-20T10:37:43.088038Z",
     "shell.execute_reply.started": "2025-03-20T10:37:40.607116Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Image-related utilities\n",
    "from torchvision.io import decode_image, read_image\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Import models\n",
    "from torchvision.models import vgg19, VGG19_Weights\n",
    "\n",
    "# Dataset\n",
    "from torchvision.datasets import Imagenette, ImageFolder\n",
    "\n",
    "# Plotting utility\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d2ff702-3cde-46a9-946a-f5409e1afafd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T10:37:43.089914Z",
     "iopub.status.busy": "2025-03-20T10:37:43.089681Z",
     "iopub.status.idle": "2025-03-20T10:37:43.204393Z",
     "shell.execute_reply": "2025-03-20T10:37:43.203860Z",
     "shell.execute_reply.started": "2025-03-20T10:37:43.089900Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# Read imagenette data into data loader\n",
    "#Process image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to VGG19 input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Same normalization as ImageNet\n",
    "])\n",
    "imagenette_data = ImageFolder(root='/home/yi/Downloads/imagenette2/val', transform=transform)\n",
    "data_loader = torch.utils.data.DataLoader(imagenette_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b81d9c16-7dc4-4c7f-b706-0bedf1f10603",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T10:37:43.205113Z",
     "iopub.status.busy": "2025-03-20T10:37:43.204949Z",
     "iopub.status.idle": "2025-03-20T10:37:43.208906Z",
     "shell.execute_reply": "2025-03-20T10:37:43.208441Z",
     "shell.execute_reply.started": "2025-03-20T10:37:43.205098Z"
    }
   },
   "outputs": [],
   "source": [
    "# For pre-trained model\n",
    "# Map number to class name\n",
    "label_to_class = {\n",
    "    0: \"English springer\",\n",
    "    1: \"French horn\",\n",
    "    2: \"cassette player\",\n",
    "    3: \"chain saw\",\n",
    "    4: \"church\",\n",
    "    5: \"garbage truck\",\n",
    "    6: \"gas pump\",\n",
    "    7: \"golf ball\",\n",
    "    8: \"parachute\",\n",
    "    9: \"tench\"\n",
    "}\n",
    "\n",
    "label_to_id = {\n",
    "    0: 217,\n",
    "    1: 566,\n",
    "    2: 482, \n",
    "    3: 491,\n",
    "    4: 497,\n",
    "    5: 569,\n",
    "    6: 571, \n",
    "    7: 574,\n",
    "    8: 701, \n",
    "    9: 0\n",
    "}\n",
    "\n",
    "# For retrained model\n",
    "# Manually rewire predicted class_id to class\n",
    "pred_to_class = {\n",
    "    1: 'English springer',\n",
    "    2: 'cassette player',\n",
    "    3: 'chain saw',\n",
    "    4: 'church',\n",
    "    5: 'French horn',\n",
    "    6: 'garbage truck',\n",
    "    7: 'gas pump',\n",
    "    8: 'golf ball',\n",
    "    9: 'parachute',\n",
    "    0: 'tench'\n",
    "}\n",
    "\n",
    "label_rewire = {\n",
    "    0: 1,\n",
    "    1: 5, \n",
    "    2: 2,\n",
    "    3: 3,\n",
    "    4: 4,\n",
    "    5: 6,\n",
    "    6: 7,\n",
    "    7: 8,\n",
    "    8: 9,\n",
    "    9: 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b057cf5-ae81-4adf-a96f-96210a38c079",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T10:37:43.210055Z",
     "iopub.status.busy": "2025-03-20T10:37:43.209906Z",
     "iopub.status.idle": "2025-03-20T10:37:45.116175Z",
     "shell.execute_reply": "2025-03-20T10:37:45.115414Z",
     "shell.execute_reply.started": "2025-03-20T10:37:43.210041Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-trained model\n",
    "'''\n",
    "weights = VGG19_Weights.DEFAULT\n",
    "model = vgg19(weights=weights).to(device)\n",
    "model.eval()\n",
    "'''\n",
    "\n",
    "# Retrained model\n",
    "PATH = 'vgg19_imagenette.pth'\n",
    "model = vgg19()\n",
    "model.classifier[6] = torch.nn.Linear(in_features=4096, out_features=10)\n",
    "model.load_state_dict(torch.load(PATH, weights_only=True))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f62d333-1eb4-452d-acd8-b4bd9f0b1548",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T10:37:45.116963Z",
     "iopub.status.busy": "2025-03-20T10:37:45.116790Z",
     "iopub.status.idle": "2025-03-20T10:38:48.030501Z",
     "shell.execute_reply": "2025-03-20T10:38:48.029940Z",
     "shell.execute_reply.started": "2025-03-20T10:37:45.116949Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████| 3925/3925 [01:02<00:00, 62.42images/s]\n"
     ]
    }
   ],
   "source": [
    "img_path = []\n",
    "true_label = []\n",
    "predicted_label = []\n",
    "confidence = []\n",
    "true_confidence = []\n",
    "correctness = []\n",
    "\n",
    "image_paths = [data_loader.dataset.samples[i][0] for i in range(len(data_loader.dataset))]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, (img, label) in enumerate(tqdm(data_loader, desc=\"Evaluating\", unit=\"images\")):\n",
    "        # Retrieve image\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        # Prediction\n",
    "        prediction = model(img).squeeze(0).softmax(0)\n",
    "        class_id = prediction.argmax().item()\n",
    "        score = prediction[class_id].item()\n",
    "        true_score = prediction[label_rewire[label.item()]].item()\n",
    "        \n",
    "        # Correct?\n",
    "        #category_name = weights.meta[\"categories\"][class_id]\n",
    "        \n",
    "        # Extract class names from the dataset\n",
    "        id_to_class = {v: k for k, v in imagenette_data.class_to_idx.items()}  # Reverse mapping\n",
    "        # Get predicted category name\n",
    "        category_name = pred_to_class[class_id]\n",
    "        # Check if prediction is correct\n",
    "        correct = 'y' if category_name == id_to_class[label.item()] else 'n'\n",
    "        \n",
    "        # Log\n",
    "        img_path.append(image_paths[idx])\n",
    "        true_label.append(id_to_class[label.item()])\n",
    "        predicted_label.append(category_name)\n",
    "        confidence.append(score)\n",
    "        true_confidence.append(true_score)\n",
    "        correctness.append(correct)\n",
    "\n",
    "# Dictionary of logs\n",
    "dict = {'image': img_path, 'true label': true_label, 'predicted label': predicted_label,\n",
    "        'confidence score': confidence, 'true confidence score': true_confidence, 'correct': correctness}\n",
    "df = pd.DataFrame(dict)\n",
    "df.to_csv('vgg19_results_retrained_imagenette.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09881061-9f11-418b-8909-c1401a8b4967",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T10:38:48.031447Z",
     "iopub.status.busy": "2025-03-20T10:38:48.031230Z",
     "iopub.status.idle": "2025-03-20T10:38:48.036926Z",
     "shell.execute_reply": "2025-03-20T10:38:48.036302Z",
     "shell.execute_reply.started": "2025-03-20T10:38:48.031425Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy:  0.9401\n"
     ]
    }
   ],
   "source": [
    "# Print evaluation accuracy\n",
    "print('Evaluation accuracy: ', round(len(df[df['correct'] == 'y']) / len(df), 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
