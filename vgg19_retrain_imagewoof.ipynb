{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d59bb5c6-f89d-47c6-a385-c83434b25062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:30:40.883955Z",
     "iopub.status.busy": "2025-04-15T13:30:40.883808Z",
     "iopub.status.idle": "2025-04-15T13:30:43.598791Z",
     "shell.execute_reply": "2025-04-15T13:30:43.598223Z",
     "shell.execute_reply.started": "2025-04-15T13:30:40.883938Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Image-related utilities\n",
    "from torchvision.io import decode_image, read_image\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Import models\n",
    "from torchvision.models import vgg19, VGG19_Weights\n",
    "from torchvision.models import vgg16, VGG16_Weights\n",
    "from torchvision.models import vgg11, VGG11_Weights\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Dataset\n",
    "from torchvision.datasets import Imagenette, ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Plotting utility\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5094b953-3a01-4074-86b1-1d6e6cef3e63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:30:43.600118Z",
     "iopub.status.busy": "2025-04-15T13:30:43.599812Z",
     "iopub.status.idle": "2025-04-15T13:30:43.748143Z",
     "shell.execute_reply": "2025-04-15T13:30:43.747586Z",
     "shell.execute_reply.started": "2025-04-15T13:30:43.600102Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize for VGG19\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # VGG preprocessing\n",
    "])\n",
    "\n",
    "# Read imagenette data into data loader\n",
    "imagewoof_train = ImageFolder(root='/home/yi/Downloads/imagewoof2/train', transform=transform)\n",
    "imagewoof_val = ImageFolder(root='/home/yi/Downloads/imagewoof2/val', transform=transform)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(imagewoof_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(imagewoof_val, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43d66d70-8839-48b0-a045-cd2ff56aea18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:30:43.748842Z",
     "iopub.status.busy": "2025-04-15T13:30:43.748689Z",
     "iopub.status.idle": "2025-04-15T13:30:43.751300Z",
     "shell.execute_reply": "2025-04-15T13:30:43.750926Z",
     "shell.execute_reply.started": "2025-04-15T13:30:43.748826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "# Get number of classes\n",
    "num_classes = len(imagewoof_train.classes)\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a1aceec-a5e1-48b1-ace5-9fec51db1f23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:30:43.752004Z",
     "iopub.status.busy": "2025-04-15T13:30:43.751836Z",
     "iopub.status.idle": "2025-04-15T13:30:45.142089Z",
     "shell.execute_reply": "2025-04-15T13:30:45.141459Z",
     "shell.execute_reply.started": "2025-04-15T13:30:43.751989Z"
    }
   },
   "outputs": [],
   "source": [
    "model_vgg19 = vgg19(weights=VGG19_Weights.DEFAULT).to(device)\n",
    "# model_vgg11 = vgg11(weights=VGG11_Weights.DEFAULT).to(device)\n",
    "# model_vgg16 = vgg16(weights=VGG16_Weights.DEFAULT).to(device)\n",
    "\n",
    "# Limit the last output features to 10\n",
    "model_vgg19.classifier[6] = nn.Linear(in_features=4096, out_features=num_classes)\n",
    "# model_vgg11.classifier[6] = nn.Linear(in_features=4096, out_features=num_classes)\n",
    "# model_vgg16.classifier[6] = nn.Linear(in_features=4096, out_features=num_classes)\n",
    "\n",
    "# Move to device\n",
    "model_vgg19 = model_vgg19.to(device)\n",
    "# model_vgg11 = model_vgg11.to(device)\n",
    "# model_vgg16 = model_vgg16.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "516bc122-c7db-461e-8a00-811b65c78df9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:30:45.142754Z",
     "iopub.status.busy": "2025-04-15T13:30:45.142609Z",
     "iopub.status.idle": "2025-04-15T13:30:45.145570Z",
     "shell.execute_reply": "2025-04-15T13:30:45.145074Z",
     "shell.execute_reply.started": "2025-04-15T13:30:45.142739Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer (fine-tuning the whole network)\n",
    "# optimizer_vgg16 = optim.Adam(model_vgg16.parameters(), lr=1e-4)\n",
    "# optimizer_vgg11 = optim.Adam(model_vgg11.parameters(), lr=1e-4)\n",
    "optimizer_vgg19 = optim.Adam(model_vgg19.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "838028ae-d66d-47b0-b7d5-f94f6117a361",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:30:45.146170Z",
     "iopub.status.busy": "2025-04-15T13:30:45.146028Z",
     "iopub.status.idle": "2025-04-15T13:30:45.158314Z",
     "shell.execute_reply": "2025-04-15T13:30:45.157916Z",
     "shell.execute_reply.started": "2025-04-15T13:30:45.146155Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 10  # Adjust as needed\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "    \n",
    "        loop = tqdm(train_loader, leave=True)\n",
    "        for images, labels in loop:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "    \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            # Compute accuracy\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "            running_loss += loss.item()\n",
    "            loop.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "            loop.set_postfix(loss=running_loss/len(train_loader), acc=100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff8f8d6d-bbb0-4875-9ba0-27c9c133fdae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:30:45.159817Z",
     "iopub.status.busy": "2025-04-15T13:30:45.159525Z",
     "iopub.status.idle": "2025-04-15T13:30:45.161996Z",
     "shell.execute_reply": "2025-04-15T13:30:45.161553Z",
     "shell.execute_reply.started": "2025-04-15T13:30:45.159800Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(model, PATH):\n",
    "    torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "796d5869-25b4-41dc-b7fa-4eb789e906d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:30:45.162700Z",
     "iopub.status.busy": "2025-04-15T13:30:45.162516Z",
     "iopub.status.idle": "2025-04-15T13:30:45.165026Z",
     "shell.execute_reply": "2025-04-15T13:30:45.164492Z",
     "shell.execute_reply.started": "2025-04-15T13:30:45.162683Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_model(model_vgg11, train_loader, criterion, optimizer_vgg11)\n",
    "# save_model(model_vgg11, \"vgg11_Imagewoof.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c77beb26-2683-4fa6-8ccf-a5c2f84d140e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:30:45.166383Z",
     "iopub.status.busy": "2025-04-15T13:30:45.166038Z",
     "iopub.status.idle": "2025-04-15T13:30:45.169030Z",
     "shell.execute_reply": "2025-04-15T13:30:45.168555Z",
     "shell.execute_reply.started": "2025-04-15T13:30:45.166355Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_model(model_vgg16, train_loader, criterion, optimizer_vgg16)\n",
    "# save_model(model_vgg16, \"vgg16_Imagewoof.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba502d2a-804d-45c4-853e-30be9b081656",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-15T13:30:45.169925Z",
     "iopub.status.busy": "2025-04-15T13:30:45.169647Z",
     "iopub.status.idle": "2025-04-15T13:57:25.604858Z",
     "shell.execute_reply": "2025-04-15T13:57:25.604366Z",
     "shell.execute_reply.started": "2025-04-15T13:30:45.169906Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]: 100%|█████| 283/283 [02:37<00:00,  1.80it/s, acc=84.5, loss=0.487]\n",
      "Epoch [2/10]: 100%|█████| 283/283 [02:38<00:00,  1.79it/s, acc=91.3, loss=0.273]\n",
      "Epoch [3/10]: 100%|█████| 283/283 [02:40<00:00,  1.76it/s, acc=93.6, loss=0.193]\n",
      "Epoch [4/10]: 100%|███████| 283/283 [02:41<00:00,  1.75it/s, acc=96, loss=0.129]\n",
      "Epoch [5/10]: 100%|█████| 283/283 [02:40<00:00,  1.76it/s, acc=96.8, loss=0.102]\n",
      "Epoch [6/10]: 100%|████| 283/283 [02:40<00:00,  1.76it/s, acc=96.8, loss=0.0957]\n",
      "Epoch [7/10]: 100%|████| 283/283 [02:38<00:00,  1.78it/s, acc=97.5, loss=0.0755]\n",
      "Epoch [8/10]: 100%|██████| 283/283 [02:41<00:00,  1.75it/s, acc=98, loss=0.0666]\n",
      "Epoch [9/10]: 100%|████| 283/283 [02:39<00:00,  1.77it/s, acc=97.3, loss=0.0843]\n",
      "Epoch [10/10]: 100%|███| 283/283 [02:40<00:00,  1.76it/s, acc=97.7, loss=0.0664]\n"
     ]
    }
   ],
   "source": [
    "train_model(model_vgg19, train_loader, criterion, optimizer_vgg19)\n",
    "# save_model(model_vgg19, \"vgg19_Imagewoof.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
